# Premier League Match Prediction Model (2020–2025)

This repository contains a Jupyter Notebook that builds and evaluates a machine learning model to predict Premier League match outcomes. The workflow is fully contained in `Premier League.ipynb`, which includes code, plots, and printed metrics in the output cells.

## Repository contents

- `Premier League.ipynb` — Main notebook with data prep, feature engineering, modeling, evaluation, and sample matchday predictions (outputs included).
- CSV season files used as input data (loaded programmatically):
  - `2017-2018.csv`
  - `2018-2019.csv`
  - `2019-2020.csv`
  - `2020-2021.csv`
  - `2021-2022.csv`
  - `2022-2023.csv`
  - `2023-2024.csv`
  - `2024-2025.csv`
  - `2025-2026.csv`
- `combined.csv` — Concatenation of all season CSVs created by the notebook.

## What the notebook does

- Loads all `20*.csv` season files in the project folder and concatenates them into a single DataFrame (and writes `combined.csv`).
- Selects and standardizes essential columns, parses dates/times, and constructs a team-centric matches dataset with home/away normalization.
- Engineers features including:
  - Encodings: `Venue_Code`, `Opp_Code`, `Day_Code`
  - Per-match stats normalized by venue: `Shots`, `Shots_On_Target`, `Corners`, `Fouls`, cards, goal metrics, and derived ratios (e.g., `Shots_Efficiency`)
  - Rolling 4-match averages per team for key metrics (e.g., `*_rolling` features)
  - Opponent rolling context features (e.g., `Opp_Points_rolling`, `Opp_Goal_Difference_rolling`, `Opp_Win_Rate_Last3_rolling`)
  - Advantage features (team minus opponent) such as `Form_Advantage`, `Goal_Diff_Advantage`, `Attack_Advantage`, `Win_Rate_Advantage`, and a simple `Home_Form_Boost`
- Splits data by date:
  - Baseline and feature-importance training on matches before `2024-01-01`
  - Evaluation on matches from `2024-01-01` onward
- Trains a RandomForestClassifier and evaluates prediction of a binary target `Target = (Result == 'Win')`.
- Reports accuracy and precision for:
  - Baseline model using 4 features: `["Venue_Code", "Opp_Code", "Time", "Day_Code"]`
  - Enhanced model using ~20 features (top rolling features + opponent context + advantage features)
- Visualizes distributions, correlations, top teams by points, win-rate trends, feature importance (top 15), and other exploratory charts.
- Provides a helper `predict_match(team, opponent, venue, time)` for single-match inference; the notebook includes sample predictions (e.g., Nov 1, 2025 fixtures).

## Results (from notebook outputs)

The notebook prints the following in its final section; refer to the output cells for the exact numbers on your data snapshot:

- Baseline metrics (4 features): Accuracy and Precision
- Best model metrics (~20 features): Accuracy and Precision
- Absolute accuracy improvement vs. baseline

Tip: Scroll to the cells that print:
- `Baseline Model (4 features)`
- `Best Model (20 features)`
- `Comparison` and `Improvement`

## Environment and dependencies

Verified imports used in the notebook:
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn (RandomForestClassifier, accuracy_score, precision_score)

You can install these with pip:

```powershell
pip install pandas numpy matplotlib seaborn scikit-learn
```

## How to run

1. Open `Premier League.ipynb` in Jupyter (VS Code or Jupyter Lab/Notebook).
2. Ensure the CSV files listed above are present in the same folder as the notebook.
3. Run all cells from top to bottom. The notebook will:
   - Load and combine the CSVs
   - Engineer features and rolling statistics
   - Train baseline and enhanced RandomForest models
   - Print evaluation metrics and render plots
   - Demonstrate `predict_match(...)` on several fixtures

If you only want to view results, open the notebook and review the rendered outputs without re-running.

## Notes

- Data selection: the code loads all local season files matching `20*.csv`. Subsequent filtering for enhanced features uses dates `>= 2020-01-01`, and evaluation uses a test split from `2024-01-01` onward.
- `combined.csv` is generated by the notebook and included here for convenience.
- No external APIs or network data sources are used; all inputs are local CSVs in this folder.
